import time
import json
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.common.exceptions import ElementClickInterceptedException, NoSuchElementException

# URL de b√∫squeda de art√≠culos en Mongabay filtrados por Latinoam√©rica, Amazon√≠a y tema "animales"
URL = "https://es.mongabay.com/?s=&locations=latinoamerica+amazonia&topics=animales&formats=post+custom_story+podcasts+specials+short_article"

# Nombre del archivo de salida
OUTPUT_FILE = "articulos.js"

# Funci√≥n para configurar el navegador Chrome en modo "headless" (sin interfaz gr√°fica)
def configurar_driver():
    options = Options()
    options.add_argument("--headless")      # Ejecutar sin ventana
    options.add_argument("--disable-gpu")   # Desactivar aceleraci√≥n gr√°fica
    options.add_argument("--window-size=1920,1080")  # Tama√±o de ventana est√°ndar
    return webdriver.Chrome(options=options)

# Funci√≥n para abrir la p√°gina y hacer clic repetidamente en "Cargar m√°s" hasta que no haya m√°s art√≠culos
def cargar_todos_los_articulos(driver):
    print(f"üåç Abriendo: {URL}")
    driver.get(URL)
    time.sleep(2)  # Espera que cargue la p√°gina inicial

    total_anterior = 0
    intentos_sin_cambio = 0  # Controla si ya no aparecen art√≠culos nuevos

    while True:
        # Hacer scroll al final de la p√°gina para cargar m√°s contenido
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)

        try:
            # Buscar y hacer clic en el bot√≥n "Cargar m√°s"
            boton = driver.find_element(By.CSS_SELECTOR, "button.load-more")
            driver.execute_script("arguments[0].scrollIntoView(true);", boton)
            time.sleep(1)
            driver.execute_script("arguments[0].click();", boton)
            print("üîÅ Clic en 'Cargar m√°s'")
            time.sleep(3)

        except NoSuchElementException:
            # Si no hay m√°s bot√≥n, se termin√≥ la carga
            print("‚úÖ No se encontr√≥ m√°s el bot√≥n 'Cargar m√°s'. Fin.")
            break

        # Verificamos si realmente se cargaron nuevos art√≠culos
        contenedores = driver.find_elements(By.CSS_SELECTOR, "div.article--container")
        total_actual = len(contenedores)

        if total_actual == total_anterior:
            intentos_sin_cambio += 1
            print(f"‚è≥ No hay nuevos art√≠culos. Intento {intentos_sin_cambio}")
        else:
            intentos_sin_cambio = 0  # Reinicia el contador si s√≠ hubo cambios

        if intentos_sin_cambio >= 3:
            break  # Rompe el bucle si ya no hay nuevos art√≠culos tras 3 intentos

        total_anterior = total_actual  # Actualiza el total para la siguiente iteraci√≥n

    return driver.page_source  # Devuelve todo el HTML cargado

# Funci√≥n para extraer los art√≠culos desde el HTML usando BeautifulSoup
def extraer_articulos(html):
    soup = BeautifulSoup(html, "html.parser")
    contenedores = soup.select("div.article--container")  # Todos los art√≠culos visuales
    articulos = []

    for cont in contenedores:
        # Extrae la URL del art√≠culo
        a_tag = cont.find("a", href=True)
        url = a_tag["href"] if a_tag else ""

        # Extrae el t√≠tulo
        titulo_tag = cont.select_one(".title h4")
        titulo = titulo_tag.get_text(strip=True) if titulo_tag else ""

        # Extrae la imagen: puede estar en src, data-src o srcset
        img_tag = cont.find("img")
        imagen = ""
        if img_tag:
            imagen = img_tag.get("src") or img_tag.get("data-src") or ""
            if not imagen and img_tag.has_attr("srcset"):
                srcset = img_tag["srcset"].split(",")[0].strip()
                imagen = srcset.split(" ")[0]

        # Extrae la fecha de publicaci√≥n
        fecha_tag = cont.select_one(".post-meta .date")
        fecha = fecha_tag.get_text(strip=True) if fecha_tag else ""

        # Solo guarda art√≠culos completos con t√≠tulo, imagen y url
        if titulo and url and imagen:
            articulos.append({
                "titulo": titulo,
                "imagen": imagen,
                "fecha": fecha,
                "url": url
            })

    return articulos

# Funci√≥n para guardar la lista de art√≠culos en un archivo JavaScript como una variable JS
def guardar_como_js(articulos):
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write("const articulos = ")
        json.dump(articulos, f, ensure_ascii=False, indent=2)  # Guarda el JSON con indentado legible
        f.write(";")
    print(f"\n‚úÖ Se guardaron {len(articulos)} art√≠culos en '{OUTPUT_FILE}'")

# Funci√≥n principal que orquesta todo el flujo
def main():
    driver = configurar_driver()            # Configura Selenium
    html = cargar_todos_los_articulos(driver)  # Carga todo el contenido din√°mico
    driver.quit()                           # Cierra el navegador

    print("üîç Extrayendo art√≠culos...")
    articulos = extraer_articulos(html)     # Extrae la info del HTML
    print(f"‚úÖ Se extrajeron {len(articulos)} art√≠culos.")
    guardar_como_js(articulos)              # Guarda como JS

# Ejecuta el script si es llamado directamente (no importado)
if __name__ == "__main__":
    main()

